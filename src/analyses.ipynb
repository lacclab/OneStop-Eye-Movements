{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05cefe4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import config\n",
    "import utils\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f71e9613",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_save_path = Path(\"figures\")\n",
    "fig_save_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbf8edc",
   "metadata": {},
   "source": [
    "## Percent validation error over 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c290a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of Trials Over 0.3 Error: 15.5%\n",
      "Percentage of Validation Errors Over 0.3: 8.9%\n"
     ]
    }
   ],
   "source": [
    "validation_error = pd.read_csv(config.BASE_PATH/'validation_error.csv')\n",
    "over_03 = validation_error[['num_over_03', 'total_trials']].sum()\n",
    "\n",
    "percentage_over_03 = round(over_03['num_over_03'] / over_03['total_trials'] * 100, 1)\n",
    "percentage_avg_error_over_03 = round((validation_error['avg_avg_val_error'] > 0.3).sum() / 360 * 100, 1)\n",
    "\n",
    "print(f\"Percentage of Trials Over 0.3 Error: {percentage_over_03}%\")\n",
    "print(f\"Percentage of Validation Errors Over 0.3: {percentage_avg_error_over_03}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71684c714035d1c6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5df81626",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = utils.load_df(config.FULL_REPORT_PATH)\n",
    "\n",
    "dat = utils.load_df(\"../data/all_dat_files_merged.tsv\") # TODO path to config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e13d9526",
   "metadata": {},
   "outputs": [],
   "source": [
    "IA_P = utils.load_df(config.IA_P_PATH)\n",
    "IA_Q = utils.load_df(config.IA_Q_PATH)\n",
    "IA_A = utils.load_df(config.IA_A_PATH)\n",
    "IA_Q_preview = utils.load_df(config.IA_Q_preview_PATH)\n",
    "IA_T = utils.load_df(config.IA_T_PATH)\n",
    "TRIAL_P = utils.load_df(config.TRIAL_P_PATH)\n",
    "TRIAL_QA = utils.load_df(config.TRIAL_QA_PATH)\n",
    "TRIAL_q_preview = utils.load_df(config.TRIAL_q_preview_PATH)\n",
    "TRIAL_T = utils.load_df(config.TRIAL_T_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0811ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of participants: 360\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total number of participants: {len(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "209fd759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique articles: 30\n"
     ]
    }
   ],
   "source": [
    "unique_articles = dat.drop_duplicates(subset=['batch','article_id']).query('practice==0')\n",
    "print(f\"Total number of unique articles: {len(unique_articles)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60f112ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique paragraphs: 162\n"
     ]
    }
   ],
   "source": [
    "unique_paragraphs = dat.drop_duplicates(subset=['batch','article_id', 'paragraph_id']).query('practice==0')\n",
    "print(f\"Total number of unique paragraphs: {len(unique_paragraphs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a5d87f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of words per paragraph: 108.6\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average number of words per paragraph: {round(unique_paragraphs['paragraph'].str.split().str.len().mean(),1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c2feebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in IA reports:\n",
      "p - 2532799\n",
      "q - 230688\n",
      "a - 912794\n",
      "q_pre - 115350\n",
      "t - 35585\n",
      "total - 3827216\n"
     ]
    }
   ],
   "source": [
    "# Calculate the lengths\n",
    "p = len(IA_P.query('practice==0'))\n",
    "q = len(IA_Q.query('practice==0'))\n",
    "a = len(IA_A.query('practice==0'))\n",
    "q_pre = len(IA_Q_preview.query('practice==0'))\n",
    "t = len(IA_T.query('practice==0'))\n",
    "total = p + q + a + t + q_pre\n",
    "\n",
    "# Consolidated print statement\n",
    "print(f\"Number of tokens in IA reports:\\np - {p}\\nq - {q}\\na - {a}\\nq_pre - {q_pre}\\nt - {t}\\ntotal - {total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b83ddb7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'onestop_qa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m unique_words_ia \u001b[38;5;241m=\u001b[39m IA_P\u001b[38;5;241m.\u001b[39mdrop_duplicates(subset\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124marticle_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparagraph_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIA_ID\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mquery(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpractice==0\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m onsqa_p \u001b[38;5;241m=\u001b[39m onestop_qa\u001b[38;5;241m.\u001b[39mdrop_duplicates(subset\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparagraph\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mquery(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel!=1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m unique_paragraphs_level \u001b[38;5;241m=\u001b[39m dat\u001b[38;5;241m.\u001b[39mdrop_duplicates(subset\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124marticle_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparagraph_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mquery(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpractice==0\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'onestop_qa' is not defined"
     ]
    }
   ],
   "source": [
    "unique_words_ia = IA_P.drop_duplicates(subset=['batch', 'article_id', 'paragraph_id', 'level', 'IA_ID']).query('practice==0')\n",
    "onsqa_p = onestop_qa.drop_duplicates(subset=['paragraph']).query('level!=1')\n",
    "unique_paragraphs_level = dat.drop_duplicates(subset=['batch', 'article_id', 'paragraph_id', 'level']).query('practice==0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36b7ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced\n",
    "adv = unique_paragraphs_level[unique_paragraphs_level['level'] == 'Adv']\n",
    "adv_tokens = [word for paragraph in utils.get_number_of_tokens(adv, \"paragraph\") for word in paragraph]\n",
    "adv_ia = unique_words_ia[unique_words_ia['level'] == 'Adv']\n",
    "adv_qa = onsqa_p[onsqa_p['level'] == 0]\n",
    "adv_qa_words = [word for paragraph in utils.get_number_of_tokens(adv_qa, \"paragraph\") for word in paragraph]\n",
    "\n",
    "print(f\"DAT Advanced Tokens Count: {len(adv_tokens)}\")\n",
    "print(f\"IA Advanced Words Count: {len(adv_ia)}\")\n",
    "print(f\"OneStopQA Advanced Words Count: {len(adv_qa_words)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2e55d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elementary\n",
    "ele = unique_paragraphs_level[unique_paragraphs_level['level'] == 'Ele']\n",
    "ele_tokens = [word for paragraph in utils.get_number_of_tokens(ele, \"paragraph\") for word in paragraph]\n",
    "ele_ia = unique_words_ia[unique_words_ia['level'] == 'Ele']\n",
    "ele_qa = onsqa_p[onsqa_p['level'] == 2]\n",
    "ele_qa_words = [word for paragraph in utils.get_number_of_tokens(ele_qa, \"paragraph\") for word in paragraph]\n",
    "\n",
    "print(f\"DAT Elementary Tokens Count: {len(ele_tokens)}\")\n",
    "print(f\"IA Elementary Words Count: {len(ele_ia)}\")\n",
    "print(f\"OneStopQA Elementary Words Count: {len(ele_qa_words)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb384788b9b7bf9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# words in OneStop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a328635c43e91d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T09:36:11.398978Z",
     "start_time": "2024-05-11T09:36:11.381608Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Advanced version\n",
    "adv_sentences = [sen for paragraph in utils.get_number_of_tokens(adv_qa, \"paragraph\") for sen in paragraph if '.' in sen]\n",
    "print(f'num words: {len(adv_qa_words)}')\n",
    "# mean paragraph length (words)\n",
    "print(f'mean paragraph length: {round(len(adv_qa_words) / len(unique_paragraphs),1)}')\n",
    "# mean sentence length (words) \n",
    "print(f'mean sentence length: {round(len(adv_qa_words) / len(adv_sentences),1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea9fcb9c1236536",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T09:36:12.903116Z",
     "start_time": "2024-05-11T09:36:12.879730Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Elementary version\n",
    "ele_sentences = [sen for paragraph in utils.get_number_of_tokens(adv, \"paragraph\") for sen in paragraph if '.' in sen]\n",
    "print(f'num words: {len(ele_qa_words)}')\n",
    "# mean paragraph length (words)\n",
    "print(f'mean paragraph length: {round(len(ele_qa_words) / len(unique_paragraphs),1)}')\n",
    "# mean sentence length (words)\n",
    "print(f'mean sentence length: {round(len(ele_qa_words) / len(ele_sentences),1)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233abf58ab7a064a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# questions (486)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e4de027dc5ebe6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T09:36:13.804757Z",
     "start_time": "2024-05-11T09:36:13.782974Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "onsqa_q = onestop_qa.drop_duplicates(subset=['paragraph_index', 'question'])\n",
    "onsqa_q_words = onsqa_q['question']\n",
    "\n",
    "unique_questions = dat.drop_duplicates(subset=['batch', 'article_id', 'paragraph_id', 'question']).query('practice==0')\n",
    "unique_qs = unique_questions['question']\n",
    "\n",
    "print(f\"Number of unique questions in OneStopQA: {len(onsqa_q)}\")\n",
    "print(f\"Average length of questions in OneStopQA: {round(utils.get_average_length(onsqa_q_words),1)}\")\n",
    "print(f\"Number of unique questions in DAT: {len(unique_questions)}\")\n",
    "print(f\"Average length of questions in DAT: {round(utils.get_average_length(unique_qs),1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32cca07705577a6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Answers (1944)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fa6c25c137ad0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T09:36:14.595547Z",
     "start_time": "2024-05-11T09:36:14.586585Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# number of answers\n",
    "a = unique_questions['a'].tolist()\n",
    "b = unique_questions['b'].tolist()\n",
    "c = unique_questions['c'].tolist()\n",
    "d = unique_questions['d'].tolist()\n",
    "unique_answers = a + b + c + d\n",
    "\n",
    "print(f\"Total Unique Answers: {len(unique_answers)}\")\n",
    "print(f\"Mean Length of 'a': {round(utils.get_average_length(a),1)}\")\n",
    "print(f\"Mean Length of 'b': {round(utils.get_average_length(b),1)}\")\n",
    "print(f\"Mean Length of 'c': {round(utils.get_average_length(c),1)}\")\n",
    "print(f\"Mean Length of 'd': {round(utils.get_average_length(d),1)}\")\n",
    "print(f\"Mean Length of All Unique Answers: {round(utils.get_average_length(unique_answers),1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bcc83440f587e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T09:36:15.216095Z",
     "start_time": "2024-05-11T09:36:15.212808Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mean length of the critical span (a_span)\n",
    "onsqa_a_span = onsqa_p['a_span']\n",
    "total_words_a = []\n",
    "for a in onsqa_a_span:\n",
    "    words = a[1] - a[0] + 1\n",
    "    total_words_a.append(words)\n",
    "mean_a = sum(total_words_a) / len(total_words_a)\n",
    "print(f\"Mean Length of Critical Span (a_span): {round(mean_a,1)}\")\n",
    "# mean length of the distractor span (d_span)\n",
    "onsqa_d_span = onsqa_p['d_span']\n",
    "total_words_d = []\n",
    "for d in onsqa_d_span:\n",
    "    words = d[1] - d[0] + 1\n",
    "    total_words_d.append(words)\n",
    "mean_d = sum(total_words_d) / len(total_words_d)\n",
    "print(f\"Mean Length of Distractor Span (d_span): {round(mean_d,1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4deecccae4f1ac68",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# participants recruited from:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5f3aa553c55fdb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T09:36:17.111862Z",
     "start_time": "2024-05-11T09:36:17.096063Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "technion_ex = ['Aya', 'Liz', 'Nethanella']\n",
    "technion = 0\n",
    "for ex in data['Experimenter']:\n",
    "    if ex in technion_ex:\n",
    "        technion = technion + 1\n",
    "mit = len(data['Experimenter']) - technion\n",
    "print(f\"Participants recruited at MIT: {mit}, Technion: {technion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793e2680508b0662",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# recalibrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdda018e59c6cfeb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T09:36:18.335712Z",
     "start_time": "2024-05-11T09:36:18.330036Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "session_interruptions = data['session_interruptions_(recalibrations)']\n",
    "print(f\"Mean number of recalibrations: {round(np.mean(session_interruptions),1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bed097062be2ad",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8027f77b2c125bce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T09:36:19.469806Z",
     "start_time": "2024-05-11T09:36:19.463586Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(f'mean duration (in minutes) - {round(np.mean(data[\"session_duration\"]),1)}')\n",
    "print(f'mean total duration (in minutes) - {round(np.mean(data[\"total_duration\"]),1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933dd93077c24cfc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T09:36:20.038652Z",
     "start_time": "2024-05-11T09:36:20.032796Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hunting = data[data['batch_condition'] == 'p']\n",
    "gathering = data[data['batch_condition'] == 'n']\n",
    "h_session_duration = hunting['session_duration']\n",
    "g_session_duration = gathering['session_duration']\n",
    "print(f'mean hunting duration - {round(np.mean(h_session_duration),1)}')\n",
    "print(f'mean gathering duration - {round(np.mean(g_session_duration),1)}')\n",
    "h_total_session_duration = hunting['total_duration']\n",
    "g_total_session_duration = gathering['total_duration']\n",
    "print(f'total mean hunting duration - {round(np.mean(h_total_session_duration),1)}')\n",
    "print(f'total mean gathering duration - {round(np.mean(g_total_session_duration),1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51583def53893ecb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T10:01:44.100569Z",
     "start_time": "2024-05-11T10:01:41.025298Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# paragraph duration\n",
    "p_duration = utils.duration_report(TRIAL_P)\n",
    "p_h_duration = p_duration[p_duration['batch_condition'] == 'p']\n",
    "p_g_duration = p_duration[p_duration['batch_condition'] == 'n']\n",
    "print(f\"p hunting - {round(p_h_duration['IP_DURATION'].mean(),1)}\")\n",
    "print(f\"p gathering - {round(p_g_duration['IP_DURATION'].mean(),1)}\")\n",
    "# q&a duration\n",
    "qa_duration = utils.duration_report(TRIAL_QA)\n",
    "qa_h_duration = qa_duration[qa_duration['batch_condition'] == 'p']\n",
    "qa_g_duration = qa_duration[qa_duration['batch_condition'] == 'n']\n",
    "print(f\"qa hunting - {round(qa_h_duration['IP_DURATION'].mean(),1)}\")\n",
    "print(f\"qa gathering - {round(qa_g_duration['IP_DURATION'].mean(),1)}\")\n",
    "# q_preview duration\n",
    "q_duration = utils.duration_report(TRIAL_q_preview)\n",
    "print(f\"q preview - {round(q_duration['IP_DURATION'].mean(),1)}\")\n",
    "merged_h_q = pd.merge(qa_h_duration, q_duration, on='RECORDING_SESSION_LABEL', suffixes=('_qa_h', '_pre_q'))\n",
    "merged_h_q['sum_qa_h_duration'] = merged_h_q['IP_DURATION_qa_h'] + merged_h_q['IP_DURATION_pre_q']\n",
    "print(round(merged_h_q['sum_qa_h_duration'].mean(),1))\n",
    "merged_qa_q = pd.merge(qa_duration, q_duration, on='RECORDING_SESSION_LABEL', suffixes=('_qa', '_pre_q'))\n",
    "merged_qa_q['sum_qa_q_duration'] = merged_qa_q['IP_DURATION_qa'] + merged_qa_q['IP_DURATION_pre_q']\n",
    "print(f\"qa+q_pre - {round(merged_qa_q['sum_qa_q_duration'].mean(),1)}\")\n",
    "t_duration = utils.duration_report(TRIAL_T)\n",
    "print(f\"t - {round(t_duration['IP_DURATION'].mean(),1)}\")\n",
    "merged_t_p = pd.merge(t_duration, p_duration, on='RECORDING_SESSION_LABEL', suffixes=('_t', '_p'))\n",
    "merged_t_p['sum_t_p_duration'] = merged_t_p['IP_DURATION_t'] + merged_t_p['IP_DURATION_p']\n",
    "print(round(merged_t_p['sum_t_p_duration'].mean(),1))\n",
    "p_t_h_duration = merged_t_p[merged_t_p['batch_condition_p'] == 'p']\n",
    "p_t_g_duration = merged_t_p[merged_t_p['batch_condition_p'] == 'n']\n",
    "print(f\"p_t hunting - {round(p_t_h_duration['sum_t_p_duration'].mean(),1)}\")\n",
    "print(f\"p_t gathering - {round(p_t_g_duration['sum_t_p_duration'].mean(),1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74ac95dfbcd0ac9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T09:36:25.640893Z",
     "start_time": "2024-05-11T09:36:25.639287Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(f\"p hunting - {round(p_duration['IP_DURATION'].mean(),1)}\")\n",
    "print(f\"p hunting - {round(p_duration['IP_DURATION'].mean(),1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714af68d09579586",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# prticipants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec0ceac",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey = data[data['age'] != -1] # TODO doesn't remove any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d4952acf376bdf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T07:17:36.663446Z",
     "start_time": "2024-05-11T07:17:36.646850Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# gender\n",
    "gender = survey['gender']\n",
    "labels, counts = np.unique(gender, return_counts=True)\n",
    "print(f'{labels[0]} - {counts[0]}, {labels[1]} - {counts[1]}, {labels[2]} - {counts[2]}')\n",
    "# The mean English Age of Acquisition\n",
    "print(f'Mean age of acquisition (AoA) - {round(np.mean(survey[\"stat_learning_english\"]),1)}')\n",
    "# participants have a university affiliation\n",
    "institutions = survey['institution']\n",
    "# print(f\"university affiliation - {survey['institution'].value_counts(dropna=False)}\")\n",
    "# print university affiliation by (text includes): mit; Technion; NaN; other\n",
    "institutions = institutions.str.lower()\n",
    "mit = institutions.str.contains('mit').sum()\n",
    "technion = institutions.str.contains('technion').sum()\n",
    "nan = institutions.isnull().sum()\n",
    "other = len(institutions) - mit - technion - nan\n",
    "print(f'University Affiliation: MIT - {mit}, Technion - {technion}, NaN - {nan}, Other - {other}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7600df72dccc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T08:50:08.273670Z",
     "start_time": "2024-05-11T08:50:08.243326Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(f'mean age - {round(np.mean(data[\"age\"]),1)}')\n",
    "print(f'std age - {round(np.std(data[\"age\"]),1)}')\n",
    "\n",
    "print(f\"Age mean - {round(survey['age'].mean(), ndigits=1)}, Age std - {round(survey['age'].std(), 1)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557cfece754a8da7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bd14223a7d8772",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T07:17:38.692300Z",
     "start_time": "2024-05-11T07:17:38.686199Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# balanced bilinguals\n",
    "# balanced_bilinguals = survey[survey['balanced_bilinguals']]\n",
    "ba_bi = survey['balanced_bilinguals'].apply(lambda x: isinstance(x, str))\n",
    "balanced_bilinguals = survey[ba_bi]\n",
    "for bb in balanced_bilinguals:\n",
    "    if 'Hebrew' in balanced_bilinguals['balanced_bilinguals']:\n",
    "        balanced_bilinguals.loc[bb, 'balanced_bilinguals'] = 'Hebrew'\n",
    "print(len(balanced_bilinguals)) # TODO is this what we want?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7247363623c73ece",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# reading comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56221699afa3af09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T07:17:42.659471Z",
     "start_time": "2024-05-11T07:17:42.617281Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reading comprehension accuracy Hunting\n",
    "comprehension_score = data.groupby(['batch_condition'])[\"comprehension_score_without_reread\"].mean()\n",
    "comprehension_hunting = comprehension_score['p']\n",
    "# reading comprehension accuracy Gathering\n",
    "comprehension_gathering = comprehension_score['n']\n",
    "\n",
    "# reading comprehension accuracy re-reading Hunting\n",
    "reread_comprehension_score = data.groupby(['batch_condition'])[\"comprehension_score_reread\"].mean()\n",
    "reread_comprehension_hunting = reread_comprehension_score['p']\n",
    "# reading comprehension accuracy re-reading Gathering\n",
    "reread_comprehension_gathering = reread_comprehension_score['n']\n",
    "\n",
    "\n",
    "print(f\"Reading Comprehension Accuracy - Hunting (without reread): {comprehension_hunting.round(1)}\")\n",
    "print(f\"Reading Comprehension Accuracy - Gathering (without reread): {comprehension_gathering.round(1)}\")\n",
    "print(f\"Reading Comprehension Accuracy - Hunting (with reread): {reread_comprehension_hunting.round(1)}\")\n",
    "print(f\"Reading Comprehension Accuracy - Gathering (with reread): {reread_comprehension_gathering.round(1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba69b9290075dc7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2febea",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey['additional_languages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7dc45fcc06c39c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T07:17:56.119554Z",
     "start_time": "2024-05-11T07:17:56.103253Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "par_dict = {}\n",
    "additional_languages = survey['additional_languages']\n",
    "par_languages = []\n",
    "speak = []\n",
    "for l in additional_languages:\n",
    "    if pd.isna(l):\n",
    "        l = ''\n",
    "        speak.append(len(l))\n",
    "    else:\n",
    "        l = list(l.split())\n",
    "        par_languages = par_languages + l\n",
    "        speak.append(len(l))\n",
    "lang, counts = np.unique(par_languages, return_counts=True)\n",
    "language = dict(zip(lang, counts))\n",
    "num_of_l, c = np.unique(speak, return_counts=True)\n",
    "num_of_languages = dict(zip(num_of_l, c))\n",
    "plus_5 = [min(p_5, 5) for p_5 in speak]\n",
    "num_of_l_5, c_5 = np.unique(plus_5, return_counts=True)\n",
    "num_of_lang_plus_5 = dict(zip(num_of_l_5, c_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db62edf9a50efd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T07:27:08.421808Z",
     "start_time": "2024-05-11T07:27:08.240857Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create the subplots\n",
    "sns.set_context(\"paper\", font_scale=2)\n",
    "fig_colors = \"#8da0cb\"  # \"#a1c9f4\"\n",
    "\n",
    "sns.set_theme(font_scale=1.5, style=\"whitegrid\")\n",
    "fig, axes = plt.subplots(ncols=3, figsize=(20, 7), sharey=True)\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "# seaborn.set_context(\"paper\", font_scale=2)\n",
    "\n",
    "# Plot 1: Countplot for Age\n",
    "age_bins = [18, 22, 32, 42, 52]\n",
    "age_labels = ['18-22', '23-32', '33-42', '43-52']\n",
    "survey = survey.copy()\n",
    "survey['age_category'] = pd.cut(survey['age'], bins=age_bins, labels=age_labels, right=False)\n",
    "sns.countplot(data=survey, x=\"age_category\", color=fig_colors, ax=axes[0], order=age_labels)\n",
    "# axes[0].xaxis.set_major_locator(ticker.MultipleLocator(5))\n",
    "# axes[0].axvline(x=survey.age.mean(), color='red', linestyle='--', linewidth=2.5)\n",
    "axes[0].set_ylabel(\"Participants\") \n",
    "axes[0].set_xlabel(\"Age\")\n",
    "\n",
    "# Plot 2: Countplot for Education\n",
    "education_order = [\"secondary\", \"college\", \"postgrad\"]\n",
    "education_labels = [\"Secondary\", \"Undergraduate\", \"Graduate\"]\n",
    "sns.countplot(data=survey, x=\"education\", color=fig_colors, ax=axes[1], order=education_order)\n",
    "axes[1].set_xticklabels(education_labels)\n",
    "axes[1].set_ylabel(\"\")\n",
    "axes[1].set_xlabel(\"Education\")\n",
    "\n",
    "# Plot 3: Barplot for Number of Additional Languages\n",
    "add_lang_labels = ['0', '1', '2', '3', '4', '5+']\n",
    "axes[2] = sns.barplot(x=list(num_of_lang_plus_5.keys()), y=list(num_of_lang_plus_5.values()), color=fig_colors, ax=axes[2])\n",
    "axes[2].set_xlabel(\"Number of Additional Languages\")\n",
    "axes[2].set_xticklabels(add_lang_labels)\n",
    "#axes[2] = seaborn.countplot(x=balanced_bilinguals['balanced_bilinguals'], color='#ff9f9b', ax=axes[2], order=balanced_bilinguals['balanced_bilinguals'].value_counts().index)\n",
    "#axes[2].set_xlabel(\"Additional Languages of Balanced Bilinguals\")\n",
    "\n",
    "#Add labels (a, b, c) to each subplot\n",
    "axes[0].text(-0.1, 1.05, 'a)', transform=axes[0].transAxes, fontsize=16, fontweight='bold', va='top')\n",
    "axes[1].text(-0.1, 1.05, 'b)', transform=axes[1].transAxes, fontsize=16, fontweight='bold', va='top')\n",
    "axes[2].text(-0.1, 1.05, 'c)', transform=axes[2].transAxes, fontsize=16, fontweight='bold', va='top')\n",
    "\n",
    "# Set facecolor for the figure only horizontal lines\n",
    "#fig.set_facecolor(color='white')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot as pdf\n",
    "plt.savefig(fig_save_path/\"demographics.pdf\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968920ce83a738c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# calibrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdf96d968a529d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T11:05:01.943894Z",
     "start_time": "2024-04-21T11:05:01.940379Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p_comprehension_score = data[data['batch_condition'] == 'p']\n",
    "n_comprehension_score = data[data['batch_condition'] == 'n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effd1fb21b73babb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T08:09:37.516565Z",
     "start_time": "2024-05-11T08:09:37.185211Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "sns.set_context(\"paper\", font_scale=2)\n",
    "sns.set_theme(font_scale=1.5, style=\"whitegrid\")\n",
    "# Create the subplots\n",
    "fig_colors = \"#8da0cb\"  # \"#a1c9f4\"\n",
    "colors = [\"#66c2a5\",\"#fc8d62\"]\n",
    "color_dict = {\n",
    "    \"p\": colors[0],\n",
    "    \"n\": colors[1],\n",
    "} \n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(20, 15), sharey=\"row\")\n",
    "\n",
    "# seaborn.set_style(style=\"whitegrid\")\n",
    "\n",
    "# Plot 1: Number of Recalibrations\n",
    "axes[0, 0] = sns.histplot(\n",
    "    data,\n",
    "    x=\"session_interruptions_(recalibrations)\",\n",
    "    color=fig_colors,\n",
    "    ax=axes[0, 0],\n",
    "    binrange=(0, 27),\n",
    "    binwidth=3,\n",
    ")\n",
    "axes[0, 0].set(ylabel=\"Participants\")\n",
    "axes[0, 0].set(xlabel=\"Recalibration Sessions\")\n",
    "axes[0, 0].axvline(session_interruptions.mean(), color=fig_colors, ls=\"--\", lw=2.5)\n",
    "axes[0, 0].set_xticks(np.arange(0, 28, 6))  # Assuming the x-axis goes from 0 to 27\n",
    "\n",
    "# Plot 2: Validations\n",
    "axes[0, 1] = sns.histplot(\n",
    "    validation_error,\n",
    "    x=\"avg_avg_val_error\",\n",
    "    color=fig_colors,\n",
    "    ax=axes[0, 1],\n",
    "    binrange=(0.1, 0.5),\n",
    "    binwidth=0.025,\n",
    ")\n",
    "axes[0, 1].set(ylabel=\"\")\n",
    "axes[0, 1].set(xlabel=\"Validation Error (degrees)\")\n",
    "axes[0, 1].axvline(\n",
    "    validation_error.avg_avg_val_error.mean(), color=fig_colors, ls=\"--\", lw=2.5\n",
    ")\n",
    "axes[0, 1].set_xticks(np.arange(0.1, 0.51, 0.1))\n",
    "\n",
    "# Plot 3: Experiment Duration\n",
    "axes[1, 0] = sns.histplot(\n",
    "    data,\n",
    "    x=\"total_duration\",\n",
    "    color=fig_colors,\n",
    "    ax=axes[1, 0],\n",
    "    binrange=(25, 115),\n",
    "    binwidth=5,\n",
    ")\n",
    "# axes[0, 1] = seaborn.histplot(DATA, x=\"session_duration\", color='purple', ax=axes[1])\n",
    "axes[1, 0].axvline(data.total_duration.mean(), color=fig_colors, ls=\"--\", lw=2.5)\n",
    "axes[1, 0].set(ylabel=\"Participants\")\n",
    "axes[1, 0].set(xlabel=\"Experiment Duration (minutes)\")\n",
    "# axes[0, 1].set_xticks()\n",
    "\n",
    "# Plot 4: Reading Comprehension Score\n",
    "condition_labels = [\n",
    "    \"Hunting\",\n",
    "    \"Gathering\",\n",
    "]\n",
    "\n",
    "\n",
    "axes[1, 1] = sns.histplot(\n",
    "    data=data,\n",
    "    x=\"comprehension_score_without_reread\",\n",
    "    palette=color_dict,\n",
    "    ax=axes[1, 1],\n",
    "    hue=\"batch_condition\",\n",
    "    multiple=\"layer\",\n",
    "    binrange=(45, 100),\n",
    "    binwidth=5,\n",
    ")\n",
    "# bins = np.linspace(40, 100, 25)\n",
    "# axes[1, 1].hist([p_comprehension_score[\"comprehension_score_without_reread\"], n_comprehension_score[\"comprehension_score_without_reread\"]], bins=bins, color=['#b9f2f0', '#d0bbff'], alpha=0.7, label=['Preview', 'No Preview'])\n",
    "# handles = [plt.Rectangle((0, 0), 1, 1, fc=color, edgecolor=\"none\") for color in colors]\n",
    "axes[1, 1].legend(\n",
    "    # handles=handles,\n",
    "    labels=condition_labels,\n",
    "    title=\"Condition\",\n",
    "    loc=\"upper left\",\n",
    ")\n",
    "axes[1, 1].set(xlabel=\"Reading Comprehension Accuracy\")\n",
    "axes[1, 1].set(ylabel=\"\")\n",
    "axes[1, 1].axvline(\n",
    "    data[data[\"batch_condition\"] == \"n\"].comprehension_score_without_reread.mean(),\n",
    "    color=colors[1],\n",
    "    ls=\"--\",\n",
    "    lw=2.5,\n",
    ")\n",
    "axes[1, 1].axvline(\n",
    "    data[data[\"batch_condition\"] == \"p\"].comprehension_score_without_reread.mean(),\n",
    "    color=colors[0],\n",
    "    ls=\"--\",\n",
    "    lw=2.5,\n",
    ")\n",
    "\n",
    "\n",
    "# Add labels (a, b, c, d) to each subplot\n",
    "axes[0, 0].text(\n",
    "    -0.1,\n",
    "    1.05,\n",
    "    \"a)\",\n",
    "    transform=axes[0, 0].transAxes,\n",
    "    fontsize=16,\n",
    "    fontweight=\"bold\",\n",
    "    va=\"top\",\n",
    ")\n",
    "axes[0, 1].text(\n",
    "    -0.1,\n",
    "    1.05,\n",
    "    \"b)\",\n",
    "    transform=axes[0, 1].transAxes,\n",
    "    fontsize=16,\n",
    "    fontweight=\"bold\",\n",
    "    va=\"top\",\n",
    ")\n",
    "axes[1, 0].text(\n",
    "    -0.1,\n",
    "    1.05,\n",
    "    \"c)\",\n",
    "    transform=axes[1, 0].transAxes,\n",
    "    fontsize=16,\n",
    "    fontweight=\"bold\",\n",
    "    va=\"top\",\n",
    ")\n",
    "axes[1, 1].text(\n",
    "    -0.1,\n",
    "    1.05,\n",
    "    \"d)\",\n",
    "    transform=axes[1, 1].transAxes,\n",
    "    fontsize=16,\n",
    "    fontweight=\"bold\",\n",
    "    va=\"top\",\n",
    ")\n",
    "\n",
    "# increase font size\n",
    "for ax in axes.flat:\n",
    "    ax.tick_params(axis=\"both\", which=\"major\", labelsize=20)\n",
    "\n",
    "# increase axis font size\n",
    "\n",
    "# Set facecolor for the figure\n",
    "fig.set_facecolor(\"white\")\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot as pdf\n",
    "plt.savefig(fig_save_path / \"exp_stats.pdf\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d3671485fa7c4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T08:03:37.331718Z",
     "start_time": "2024-05-11T08:03:37.291797Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_calibrations_per_session = sum(data['total_recalibrations']) / sum(data['session_interruptions_(recalibrations)'])\n",
    "print(f\"Mean number of calibrations per-recalibration session: {round(mean_calibrations_per_session,1)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
